{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# prerequisites\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "bs = 100\n",
    "\n",
    "# MNIST Dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transform, download=False)\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, g_input_dim, g_output_dim):\n",
    "        super(Generator, self).__init__()       \n",
    "        self.fc1 = nn.Linear(g_input_dim, 256)\n",
    "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\n",
    "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)\n",
    "        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)\n",
    "    \n",
    "    # forward method\n",
    "    def forward(self, x): \n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        return torch.tanh(self.fc4(x))\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, d_input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_input_dim, 1024)\n",
    "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features//2)\n",
    "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features//2)\n",
    "        self.fc4 = nn.Linear(self.fc3.out_features, 1)\n",
    "    \n",
    "    # forward method\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        return torch.sigmoid(self.fc4(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# build network\n",
    "z_dim = 100\n",
    "mnist_dim = train_dataset.train_data.size(1) * train_dataset.train_data.size(2)\n",
    "\n",
    "G = Generator(g_input_dim = z_dim, g_output_dim = mnist_dim).to(device)\n",
    "D = Discriminator(mnist_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Generator(\n  (fc1): Linear(in_features=100, out_features=256, bias=True)\n  (fc2): Linear(in_features=256, out_features=512, bias=True)\n  (fc3): Linear(in_features=512, out_features=1024, bias=True)\n  (fc4): Linear(in_features=1024, out_features=784, bias=True)\n)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 45
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Discriminator(\n  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n  (fc3): Linear(in_features=512, out_features=256, bias=True)\n  (fc4): Linear(in_features=256, out_features=1, bias=True)\n)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 46
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# loss\n",
    "criterion = nn.BCELoss() \n",
    "\n",
    "# optimizer\n",
    "lr = 0.0002 \n",
    "G_optimizer = optim.Adam(G.parameters(), lr = lr)\n",
    "D_optimizer = optim.Adam(D.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def D_train(x):\n",
    "    #=======================Train the discriminator=======================#\n",
    "    D.zero_grad()\n",
    "\n",
    "    # train discriminator on real\n",
    "    x_real, y_real = x.view(-1, mnist_dim), torch.ones(bs, 1)\n",
    "    x_real, y_real = Variable(x_real.to(device)), Variable(y_real.to(device))\n",
    "\n",
    "    D_output = D(x_real)\n",
    "    D_real_loss = criterion(D_output, y_real)\n",
    "    D_real_score = D_output\n",
    "\n",
    "    # train discriminator on facke\n",
    "    z = Variable(torch.randn(bs, z_dim).to(device))\n",
    "    x_fake, y_fake = G(z), Variable(torch.zeros(bs, 1).to(device))\n",
    "\n",
    "    D_output = D(x_fake)\n",
    "    D_fake_loss = criterion(D_output, y_fake)\n",
    "    D_fake_score = D_output\n",
    "\n",
    "    # gradient backprop & optimize ONLY D's parameters\n",
    "    D_loss = D_real_loss + D_fake_loss\n",
    "    D_loss.backward()\n",
    "    D_optimizer.step()\n",
    "        \n",
    "    return  D_loss.data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def G_train(x):\n",
    "    #=======================Train the generator=======================#\n",
    "    G.zero_grad()\n",
    "\n",
    "    z = Variable(torch.randn(bs, z_dim).to(device))\n",
    "    y = Variable(torch.ones(bs, 1).to(device))\n",
    "\n",
    "    G_output = G(z)\n",
    "    D_output = D(G_output)\n",
    "    G_loss = criterion(D_output, y)\n",
    "\n",
    "    # gradient backprop & optimize ONLY G's parameters\n",
    "    G_loss.backward()\n",
    "    G_optimizer.step()\n",
    "        \n",
    "    return G_loss.data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[1/101]: loss_d: 0.801, loss_g: 3.637\n",
      "[2/101]: loss_d: 0.704, loss_g: 4.215\n",
      "[3/101]: loss_d: 0.851, loss_g: 2.454\n",
      "[4/101]: loss_d: 0.587, loss_g: 2.946\n",
      "[5/101]: loss_d: 0.468, loss_g: 3.058\n",
      "[6/101]: loss_d: 0.420, loss_g: 3.313\n",
      "[7/101]: loss_d: 0.504, loss_g: 2.880\n",
      "[8/101]: loss_d: 0.581, loss_g: 2.549\n",
      "[9/101]: loss_d: 0.552, loss_g: 2.650\n",
      "[10/101]: loss_d: 0.639, loss_g: 2.361\n",
      "[11/101]: loss_d: 0.699, loss_g: 2.164\n",
      "[12/101]: loss_d: 0.707, loss_g: 2.093\n",
      "[13/101]: loss_d: 0.791, loss_g: 1.957\n",
      "[14/101]: loss_d: 0.804, loss_g: 1.913\n",
      "[15/101]: loss_d: 0.778, loss_g: 1.933\n",
      "[16/101]: loss_d: 0.794, loss_g: 1.888\n",
      "[17/101]: loss_d: 0.798, loss_g: 1.938\n",
      "[18/101]: loss_d: 0.846, loss_g: 1.781\n",
      "[19/101]: loss_d: 0.870, loss_g: 1.702\n",
      "[20/101]: loss_d: 0.873, loss_g: 1.669\n",
      "[21/101]: loss_d: 0.877, loss_g: 1.692\n",
      "[22/101]: loss_d: 0.877, loss_g: 1.670\n",
      "[23/101]: loss_d: 0.909, loss_g: 1.628\n",
      "[24/101]: loss_d: 0.938, loss_g: 1.536\n",
      "[25/101]: loss_d: 0.981, loss_g: 1.478\n",
      "[26/101]: loss_d: 0.961, loss_g: 1.519\n",
      "[27/101]: loss_d: 0.977, loss_g: 1.455\n",
      "[28/101]: loss_d: 0.967, loss_g: 1.469\n",
      "[29/101]: loss_d: 0.980, loss_g: 1.424\n",
      "[30/101]: loss_d: 1.015, loss_g: 1.365\n",
      "[31/101]: loss_d: 1.024, loss_g: 1.346\n",
      "[32/101]: loss_d: 1.022, loss_g: 1.354\n",
      "[33/101]: loss_d: 1.025, loss_g: 1.354\n",
      "[34/101]: loss_d: 1.041, loss_g: 1.344\n",
      "[35/101]: loss_d: 1.024, loss_g: 1.354\n",
      "[36/101]: loss_d: 1.057, loss_g: 1.298\n",
      "[37/101]: loss_d: 1.055, loss_g: 1.293\n",
      "[38/101]: loss_d: 1.075, loss_g: 1.252\n",
      "[39/101]: loss_d: 1.087, loss_g: 1.235\n",
      "[40/101]: loss_d: 1.096, loss_g: 1.220\n",
      "[41/101]: loss_d: 1.115, loss_g: 1.183\n",
      "[42/101]: loss_d: 1.121, loss_g: 1.175\n",
      "[43/101]: loss_d: 1.136, loss_g: 1.142\n",
      "[44/101]: loss_d: 1.135, loss_g: 1.146\n",
      "[45/101]: loss_d: 1.146, loss_g: 1.122\n",
      "[46/101]: loss_d: 1.138, loss_g: 1.134\n",
      "[47/101]: loss_d: 1.145, loss_g: 1.112\n",
      "[48/101]: loss_d: 1.154, loss_g: 1.108\n",
      "[49/101]: loss_d: 1.152, loss_g: 1.106\n",
      "[50/101]: loss_d: 1.159, loss_g: 1.105\n",
      "[51/101]: loss_d: 1.160, loss_g: 1.093\n",
      "[52/101]: loss_d: 1.158, loss_g: 1.094\n",
      "[53/101]: loss_d: 1.169, loss_g: 1.080\n",
      "[54/101]: loss_d: 1.179, loss_g: 1.061\n",
      "[55/101]: loss_d: 1.178, loss_g: 1.061\n",
      "[56/101]: loss_d: 1.175, loss_g: 1.060\n",
      "[57/101]: loss_d: 1.189, loss_g: 1.052\n",
      "[58/101]: loss_d: 1.198, loss_g: 1.013\n",
      "[59/101]: loss_d: 1.192, loss_g: 1.032\n",
      "[60/101]: loss_d: 1.201, loss_g: 1.023\n",
      "[61/101]: loss_d: 1.191, loss_g: 1.045\n",
      "[62/101]: loss_d: 1.192, loss_g: 1.039\n",
      "[63/101]: loss_d: 1.207, loss_g: 1.015\n",
      "[64/101]: loss_d: 1.207, loss_g: 1.028\n",
      "[65/101]: loss_d: 1.199, loss_g: 1.020\n",
      "[66/101]: loss_d: 1.200, loss_g: 1.022\n",
      "[67/101]: loss_d: 1.202, loss_g: 1.014\n",
      "[68/101]: loss_d: 1.214, loss_g: 0.999\n",
      "[69/101]: loss_d: 1.212, loss_g: 0.998\n",
      "[70/101]: loss_d: 1.211, loss_g: 1.011\n",
      "[71/101]: loss_d: 1.211, loss_g: 1.011\n",
      "[72/101]: loss_d: 1.199, loss_g: 1.030\n",
      "[73/101]: loss_d: 1.227, loss_g: 0.974\n",
      "[74/101]: loss_d: 1.223, loss_g: 0.998\n",
      "[75/101]: loss_d: 1.215, loss_g: 0.985\n",
      "[76/101]: loss_d: 1.229, loss_g: 0.986\n",
      "[77/101]: loss_d: 1.232, loss_g: 0.982\n",
      "[78/101]: loss_d: 1.215, loss_g: 1.006\n",
      "[79/101]: loss_d: 1.222, loss_g: 0.982\n",
      "[80/101]: loss_d: 1.231, loss_g: 0.960\n",
      "[81/101]: loss_d: 1.232, loss_g: 0.968\n",
      "[82/101]: loss_d: 1.234, loss_g: 0.959\n",
      "[83/101]: loss_d: 1.233, loss_g: 0.978\n",
      "[84/101]: loss_d: 1.229, loss_g: 0.976\n",
      "[85/101]: loss_d: 1.231, loss_g: 0.969\n",
      "[86/101]: loss_d: 1.246, loss_g: 0.944\n",
      "[87/101]: loss_d: 1.240, loss_g: 0.962\n",
      "[88/101]: loss_d: 1.238, loss_g: 0.964\n",
      "[89/101]: loss_d: 1.241, loss_g: 0.947\n",
      "[90/101]: loss_d: 1.244, loss_g: 0.955\n",
      "[91/101]: loss_d: 1.245, loss_g: 0.950\n",
      "[92/101]: loss_d: 1.247, loss_g: 0.940\n",
      "[93/101]: loss_d: 1.252, loss_g: 0.959\n",
      "[94/101]: loss_d: 1.246, loss_g: 0.953\n",
      "[95/101]: loss_d: 1.247, loss_g: 0.951\n",
      "[96/101]: loss_d: 1.258, loss_g: 0.934\n",
      "[97/101]: loss_d: 1.256, loss_g: 0.935\n",
      "[98/101]: loss_d: 1.254, loss_g: 0.932\n",
      "[99/101]: loss_d: 1.256, loss_g: 0.930\n",
      "[100/101]: loss_d: 1.252, loss_g: 0.945\n",
      "[101/101]: loss_d: 1.249, loss_g: 0.934\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "n_epoch = 101\n",
    "for epoch in range(1, n_epoch+1):           \n",
    "    D_losses, G_losses = [], []\n",
    "    for batch_idx, (x, _) in enumerate(train_loader):\n",
    "        D_losses.append(D_train(x))\n",
    "        G_losses.append(G_train(x))\n",
    "\n",
    "    print('[%d/%d]: loss_d: %.3f, loss_g: %.3f' % (\n",
    "            (epoch), n_epoch, torch.mean(torch.FloatTensor(D_losses)), torch.mean(torch.FloatTensor(G_losses))))\n",
    "    with torch.no_grad():\n",
    "        test_z = Variable(torch.randn(bs, z_dim).to(device))\n",
    "        generated = G(test_z)\n",
    "        save_image(generated.view(generated.size(0), 1, 28, 28), 'samples/sample_%d.png' % epoch, nrow=10, normalize=True)\n",
    "    \n",
    "    if (epoch-1) % 50 == 0:\n",
    "        torch.save(G.state_dict(), os.path.join('samples', 'G--{}.ckpt'.format(epoch+1)))\n",
    "        torch.save(D.state_dict(), os.path.join('samples', 'D--{}.ckpt'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_z = Variable(torch.randn(bs, z_dim).to(device))\n",
    "    generated = G(test_z)\n",
    "\n",
    "    save_image(generated.view(generated.size(0), 1, 28, 28), './samples/sample_' + '.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "ori_sample = Variable(torch.randn(bs, z_dim).to(device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor(-0.0597)\n",
      "tensor(-0.0567)\n",
      "tensor(-0.0537)\n",
      "tensor(-0.0507)\n",
      "tensor(-0.0477)\n",
      "tensor(-0.0447)\n",
      "tensor(-0.0417)\n",
      "tensor(-0.0387)\n",
      "tensor(-0.0357)\n",
      "tensor(-0.0327)\n",
      "tensor(-0.0297)\n",
      "tensor(-0.0267)\n",
      "tensor(-0.0237)\n",
      "tensor(-0.0207)\n",
      "tensor(-0.0177)\n",
      "tensor(-0.0147)\n",
      "tensor(-0.0117)\n",
      "tensor(-0.0087)\n",
      "tensor(-0.0057)\n",
      "tensor(-0.0027)\n",
      "tensor(0.0003)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "sample = ori_sample.clone()\n",
    "sample[:,0:100:4] -= 1\n",
    "sample[:,1:100:5] += 1\n",
    "for ii in range(0, 21):\n",
    "    sample[:,0:50:4] += 0.1\n",
    "    sample[:,1:51:5] -= 0.1\n",
    "    print(torch.mean(sample))\n",
    "    generated = G(sample)\n",
    "    save_image(generated.view(generated.size(0), 1, 28, 28)[13,:],\n",
    "                       'samples/pertubation_test_' + str(ii) + '.png', nrow=10)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-6e959d29",
   "language": "python",
   "display_name": "PyCharm (proj)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
